{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arthu\\AppData\\Local\\Temp\\ipykernel_19052\\1181802491.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  data_frame = pd.read_csv(caminho_arquivo, header=None, delimiter='/t')  # Pode ajustar o delimitador conforme necessário\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://aura.gesdisc.eosdis.nasa.gov/daac-bin/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://aura.gesdisc.eosdis.nasa.gov/daac-bin/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://aura.gesdisc.eosdis.nasa.gov/daac-bin/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://aura.gesdisc.eosdis.nasa.gov/daac-bin/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://aura.gesdisc.eosdis.nasa.gov/daac-bin/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>https://aura.gesdisc.eosdis.nasa.gov/daac-bin/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>https://aura.gesdisc.eosdis.nasa.gov/daac-bin/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>https://aura.gesdisc.eosdis.nasa.gov/daac-bin/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>https://aura.gesdisc.eosdis.nasa.gov/daac-bin/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>https://aura.gesdisc.eosdis.nasa.gov/daac-bin/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>629 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0\n",
       "0    https://aura.gesdisc.eosdis.nasa.gov/daac-bin/...\n",
       "1    https://aura.gesdisc.eosdis.nasa.gov/daac-bin/...\n",
       "2    https://aura.gesdisc.eosdis.nasa.gov/daac-bin/...\n",
       "3    https://aura.gesdisc.eosdis.nasa.gov/daac-bin/...\n",
       "4    https://aura.gesdisc.eosdis.nasa.gov/daac-bin/...\n",
       "..                                                 ...\n",
       "624  https://aura.gesdisc.eosdis.nasa.gov/daac-bin/...\n",
       "625  https://aura.gesdisc.eosdis.nasa.gov/daac-bin/...\n",
       "626  https://aura.gesdisc.eosdis.nasa.gov/daac-bin/...\n",
       "627  https://aura.gesdisc.eosdis.nasa.gov/daac-bin/...\n",
       "628  https://aura.gesdisc.eosdis.nasa.gov/daac-bin/...\n",
       "\n",
       "[629 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Substitua 'seu_arquivo.txt' pelo caminho real do seu arquivo de texto\n",
    "caminho_arquivo = 'subset_OMTO3_003_20231116_135047_.txt'\n",
    "\n",
    "# Ler o arquivo de texto sem cabeçalhos\n",
    "data_frame = pd.read_csv(caminho_arquivo, header=None, delimiter='/t')  # Pode ajustar o delimitador conforme necessário\n",
    "\n",
    "# Exibir o DataFrame\n",
    "display(data_frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from osgeo import gdal\n",
    "\n",
    "def extrair_nome_do_arquivo(url):\n",
    "    # Usando expressão regular para encontrar a parte após \"LABEL=\"\n",
    "    match = re.search(r'LABEL=(.*?)&', url)\n",
    "    \n",
    "    if match:\n",
    "        # Obtendo o valor correspondente ao grupo capturado na expressão regular\n",
    "        nome_do_arquivo = match.group(1)\n",
    "        # Decodificando caracteres especiais da URL\n",
    "        nome_do_arquivo_decodificado = nome_do_arquivo.replace('%2F', '/').replace('%20', ' ')\n",
    "        return nome_do_arquivo_decodificado\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def convert_nc4_to_geotiff(input_nc4, output_geotiff):\n",
    "    # Open the NetCDF file\n",
    "    dataset = gdal.Open(input_nc4, gdal.GA_ReadOnly)\n",
    "\n",
    "    # Create GeoTIFF driver\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "\n",
    "    # Create the output GeoTIFF file\n",
    "    output_dataset = driver.CreateCopy(output_geotiff, dataset)\n",
    "\n",
    "    # Close the datasets\n",
    "    dataset = None\n",
    "    output_dataset = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "contents of URL written to ozone_0.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_1.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_2.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_3.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_4.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_5.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_6.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_7.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_8.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_9.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_10.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_11.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_12.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_13.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_14.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_15.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_16.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_17.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_18.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_19.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_20.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_21.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_22.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_23.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_24.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_25.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_26.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_27.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_28.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_29.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_30.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_31.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_32.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_33.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_34.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_35.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_36.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_37.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_38.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_39.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_40.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_41.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_42.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_43.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_44.nc4\n",
      "<Response [200]>\n",
      "contents of URL written to ozone_45.nc4\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "# Set the URL string to point to a specific data URL. Some generic examples are:\n",
    "#   https://data.gesdisc.earthdata.nasa.gov/data/MERRA2/path/to/granule.nc4\n",
    "for i in range(data_frame.shape[0]):\n",
    "\n",
    "    URL = data_frame[0][i]\n",
    "    # Name base on the URL Label=\n",
    "\n",
    "    # Load cookies from Chrome\n",
    "    cookies = 'eyJ0eXAiOiJKV1QiLCJvcmlnaW4iOiJFYXJ0aGRhdGEgTG9naW4iLCJzaWciOiJlZGxqd3RwdWJrZXlfb3BzIiwiYWxnIjoiUlMyNTYifQ.eyJ0eXBlIjoiVXNlciIsInVpZCI6ImFydGh1cjI2MzAiLCJleHAiOjE3MDUzMzA4MzUsImlhdCI6MTcwMDE0NjgzNSwiaXNzIjoiRWFydGhkYXRhIExvZ2luIn0.gP9Gud-LorcErattrjWZpA6aRwMOX7g1SMayOfug8KbA1tFifhcchpu6yygeBQHbjYbuFm_V9BiXBQrgbUxb2nOyOHoOSBfhZ3yAehUf3duzWolgGQC5dZQsECCRExGCZ7iXrCdk1mlF_pkKOgAcpVlREzzqeInYxCZHFcau25bhx6M-C-G6al5psE6lmK_BaFJSUVfkYiPxiSe17yxONrhVpBOk9-wEumlMGesdHSpV1X6ZYzszwi_gGawq7WR_MyV6Kd9Hj0Ey0JZcdVwr6-BtP3Gp9J7TuZJhvcHvTPJZVDKl0uUU7byC6B7Thi7TcmI69xRbnwo81ainYvybFg'\n",
    "\n",
    "    # Set the FILENAME string to the data file name, the LABEL keyword value, or any customized name. \n",
    "    FILENAME = extrair_nome_do_arquivo(URL)\n",
    "\n",
    "    # # Set password and username as strings\n",
    "    # #   If the data is public, no need to set the username and password\n",
    "    # #   If the data is private, set the username and password\n",
    "    # #   If the data is public but the server requires authentication, set the username and password\n",
    "    # USERNAME = 'Arthur2630'\n",
    "    # PASSWORD = '!3#kG@G*WRRGB.Q'\n",
    "\n",
    "    result = requests.get(URL, headers={'Authorization': 'Bearer ' + cookies})\n",
    "    print(result)\n",
    "    try:\n",
    "        result.raise_for_status()\n",
    "        f = open(FILENAME,'wb')\n",
    "        f.write(result.content)\n",
    "        f.close()\n",
    "        print('contents of URL written to '+FILENAME)\n",
    "    except:\n",
    "        print('requests.get() returned an error code '+str(result.status_code))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
